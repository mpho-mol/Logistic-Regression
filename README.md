Logistic regression is a statistical method used for binary classification and, in some cases, multiclass classification problems. Binary classification refers to when the dependent variable is binary, so it has only two possible classes or outcomes. For example: 0 or 1, True or False, Yes or No. Despite its name, unlike linear regression which is a regression algorithm used for continuous target variables, it is a classification algorithm used to predict the probability that a given input belongs to a certain class. Logistic regression uses the logistic or sigmoid function to model the relationship between the independent variables and the probability of the dependent variable belonging to one of the two predetermined classes. The logistic function is an S-shaped curve mapping any real-valued numbers to a value between 0 and 1. The logistic function is expressed as P(Y = 1) = 1/(1+e*(-(a+bX))). X represents the independent variables. P(Y=1) is the probability that the outcome or dependent variable is in class 1. Then a and b are the intercept and coefficient associated with X respectively. The logistic regression model estimates the values of a and b which best fit the empirical data. Logistic regression creates a decision boundary that separates the two classes bases on the given function. The boundary is normally adjusted to P(Y=1)=0.5. So if the calculated probability is greater than 0.5, the input is classified as class 1; and if it is less than 0.5, it's classified as class 0. Logistic regression is related to machine learning because it is a supervised learning algorithm where every input is associated with a labelled class. It is often used as a benchmark model for binary classification problems as it is a classification algorithm. The coefficients indicate the significance and the positive or negative impact of each feature on the probability of belonging to a certain class. These probability estimates can be used to assess the confidence of the model's predictions.

The task is completed in Jupyter Notebook using the Iris data set, which consists of three classes of irises. The aim was to generate a classifier predicting whether an iris belongs to the 'Iris-setosa' class or not-'Iris-setosa'class.
Firstly, the independent variables x were identified. Then the dependent variable y was encoded using mapping such that 'Iris-setosa' is encoded as 0 and 'Iris-versicolor' and 'Iris -virginica' (not-'Iris-setosa) are both encoded as 1. The data was then split into a train and test set. A model was created and fitted, with predictions made on the test set. A confusion matrix as computed and analysed in order to compare the predicted labels to the actual labels and provide a prediction on the model's precision and recall.
